
(base) C:\Users\Dyn\Documents\yelp_dataset\analysis>python StarPredictionBasicModels.py
start loading data
end loading data, time elapsed: 0.179 second


end preparing data, time elapsed: 13.251 second


training set dimension: (16000, 55700)
test set dimension: (4000, 55700)
training set target dimension: (16000,)
test set target dimension: (4000,)


********************************************************************************
running model : logistic Regression on TFIDF
logistic Regression  (tfidf) best estimator :
 LogisticRegression(C=1, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)

logistic Regression  (tfidf) best roc auc score :  0.869

logistic Regression  (tfidf) auc:
0  :  0.954
1  :  0.888
2  :  0.790
3  :  0.751
4  :  0.868
micro  :  0.870
macro  :  0.851
end training model logistic Regression, time elapsed: 240.710 second


********************************************************************************
running model : Bernoulli Naive Bayes on TFIDF
Bernoulli Naive Bayes  (tfidf) best estimator :
 BernoulliNB(alpha=0.05, binarize=0.0, class_prior=None, fit_prior=True)

Bernoulli Naive Bayes  (tfidf) best roc auc score :  0.826

Bernoulli Naive Bayes  (tfidf) auc:
0  :  0.936
1  :  0.848
2  :  0.756
3  :  0.689
4  :  0.793
micro  :  0.826
macro  :  0.805
end training model Bernoulli Naive Bayes, time elapsed: 5.333 second


********************************************************************************
running model : Random Forest on TFIDF
Random Forest  (tfidf) best estimator :
 RandomForestClassifier(bootstrap=True, class_weight='balanced',
            criterion='gini', max_depth=32, max_features='auto',
            max_leaf_nodes=None, min_impurity_decrease=0.0,
            min_impurity_split=None, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=500, n_jobs=-1, oob_score=False,
            random_state=1234, verbose=0, warm_start=False)

Random Forest  (tfidf) best roc auc score :  0.845

Random Forest  (tfidf) auc:
0  :  0.948
1  :  0.870
2  :  0.755
3  :  0.695
4  :  0.829
micro  :  0.842
macro  :  0.820
end training model Random Forest, time elapsed: 453.042 second


********************************************************************************
running model : Support Vector Classifier on SVD
Support Vector Classifier  (tfidf) best estimator :
 SVC(C=10, cache_size=200, class_weight='balanced', coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=True, random_state=1234, shrinking=True,
  tol=0.001, verbose=False)

Support Vector Classifier  (tfidf) best roc auc score :  0.870

Support Vector Classifier  (tfidf) auc:
0  :  0.954
1  :  0.885
2  :  0.799
3  :  0.756
4  :  0.858
micro  :  0.869
macro  :  0.851
end training model Support Vector Classifier, time elapsed: 4531.283 second


********************************************************************************
running model : XGboost on TFIDF
XGboost  (tfidf) best estimator :
 XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=0.2, gamma=0, learning_rate=0.05, max_delta_step=0,
       max_depth=9, min_child_weight=1, missing=None, n_estimators=200,
       n_jobs=1, nthread=-1, objective='multi:softprob', random_state=0,
       reg_alpha=0.5, reg_lambda=0.5, scale_pos_weight=1, seed=None,
       silent=1, subsample=0.8)

XGboost  (tfidf) best roc auc score :  0.854

XGboost  (tfidf) auc:
0  :  0.948
1  :  0.879
2  :  0.777
3  :  0.725
4  :  0.840
micro  :  0.851
macro  :  0.834
end training model XGboost, time elapsed: 36458.578 second


********************************************************************************
running model : lightGBM on TFIDF

lightGBM  (tfidf) best estimator :
 LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.2,
        learning_rate=0.05, max_depth=-1, min_child_samples=20,
        min_child_weight=0.001, min_split_gain=0.0, n_estimators=200,
        n_jobs=-1, num_leaves=31, objective=None, random_state=None,
        reg_alpha=0.2, reg_lambda=0.8, silent=1, subsample=0.8,
        subsample_for_bin=200000, subsample_freq=1)

lightGBM  (tfidf) best roc auc score :  0.864

lightGBM  (tfidf) auc:
0  :  0.949
1  :  0.891
2  :  0.786
3  :  0.744
4  :  0.852
micro  :  0.861
macro  :  0.845
end training model lightGBM, time elapsed: 9969.859 second



(base) C:\Users\Dyn\Documents\yelp_dataset\analysis>